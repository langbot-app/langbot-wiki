# Modify Dialogue Pipeline Configuration (Pipelines)

The pipeline controls the processing flow after receiving a message, as well as the information exchange with the large language model. Each bot can be bound to one pipeline, and the same pipeline can be bound to multiple bots.

LangBot automatically creates a default pipeline when first started. When creating a bot, it is automatically bound to the default pipeline. When creating the first model, it is automatically set as the model for the default pipeline.

![arch](/assets/image/zh/deploy/pipelines/arch.png)

You can create multiple pipelines for different bots to adapt to different scenarios.



The current pipeline can be configured with the following features:

## AI Capabilities

You can choose to use: `Built-in Agent`, [`Dify`](https://dify.ai/), [`n8n`](https://n8n.io/)

AI capabilities are mainly divided into two parts: selecting the runner and configuring runner parameters.

The runner defines how to schedule the large model to process messages. The default is `Built-in Agent`, which is a multi-round Agent strategy implemented by LangBot. Only when this runner is selected will the models and tools configured internally in LangBot be used.

*<!-- ![edit_pipeline](/assets/image/zh/deploy/pipelines/edit_pipeline_ai.png) -->*

<img width="400px" src="/assets/image/zh/deploy/pipelines/edit_pipeline_ai.png" alt="edit_pipeline" />

You can also choose to use external LLMOps platforms such as `Dify`, [`n8n`](https://n8n.io/). In this case, the models, prompts, tools, and other resources used will be provided by the LLMOps platform.

<img width="400px" src="/assets/image/zh/deploy/pipelines/more_runner.png" alt="more_runner" />

- For detailed steps on connecting to Dify, you can [refer to the tutorial](/en/deploy/pipelines/dify.html).
- For detailed steps on connecting to n8n, you can [refer to the tutorial](/en/deploy/pipelines/n8n.html).

### Conversation Variables
When using external LLMOps platforms, LangBot explicitly passes the following parameters, which you can add to the start node of the LLMOps platform workflow (the image below is an example of Dify):

- `launcher_type`: Launcher object type, `person` for private chat, `group` for group chat
- `launcher_id`: Launcher object ID, user ID for private chat, group ID for group chat
- `sender_id`: Sender ID
- `user_message_text`: The plain text of the user message
- `session_id`: User session ID, `person_<id>` for private chat, `group_<id>` for group chat
- `conversation_id`: String, user session ID, generated by LangBot. It will be regenerated after the user resets the session
- `msg_create_time`: Numeric type, timestamp (seconds) when this message was received  
- `group_name`: Group name, only set when receiving group messages
- `sender_name`: Sender name

You can [customize any variable through plugins](/en/plugin/dev/apis/common.html#set-request-variables).

![Dify Workflow Start Node Configuration](/assets/image/en/workshop/dify-service-api/dify_workflow_var.png)

## Other Configurations

Please refer to the descriptions in the configuration form.
